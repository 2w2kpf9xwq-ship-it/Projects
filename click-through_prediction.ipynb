{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665e4927-699b-44b3-bb19-54dbf314bcb3",
   "metadata": {},
   "source": [
    "# Decision tree click-through prediction project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cda271-be03-4b30-9634-893b41da78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241a70ea-d0f9-456d-a637-2369d4c91346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First metric for measuring a split: weighted Gini impurity.\n",
    "def gini_impurity_weighted(labels, class_weight):\n",
    "    # Count the occurrences of each label.\n",
    "    classes, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    weighted_counts = np.array([\n",
    "        counts[c] * class_weight.get(classes[c], 1.0) for c in range(len(classes))\n",
    "    ])\n",
    "    total = weighted_counts.sum()\n",
    "\n",
    "    # When the set is empty, it is also pure.\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    fractions = weighted_counts / total\n",
    "    return 1.0 - np.sum(fractions ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e145c0-d3d5-49d9-9e9f-fd4ca0272962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second metric for measuring a split: weighted entropy.\n",
    "def entropy_weighted(labels):\n",
    "    classes, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    weighted_counts = np.array([\n",
    "        counts[i] * class_weight.get(classes[i], 1.0) for i in range(len(classes))\n",
    "    ])\n",
    "    total = weighted_counts.sum()\n",
    "\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    fractions = weighted_counts / total\n",
    "    # The fractions are probabilities, so they have to be >= 0.\n",
    "    fractions = fractions[fractions > 0]\n",
    "    return - np.sum(fractions * np.log2(fractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b516af-039f-468b-a3e2-0cbbf4175529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we combine the two metrics into one function to calculate the weighted impurity.\n",
    "criterion_function = {'gini': gini_impurity_weighted, 'entropy': entropy_weighted}\n",
    "\n",
    "def weighted_impurity(groups, criterion='gini', class_weight=None):\n",
    "    \"\"\"\n",
    "    Calculate weighted impurity of children after a split.\n",
    "    @param groups: list of children, and a child consists a list of class labels.\n",
    "    @param criterion: metric to measure the quality of a split, 'gini' for weighted Gini impurity or 'entropy' for weighted information gain.\n",
    "    @return: float, weighted impurity.\n",
    "    \"\"\"\n",
    "    total_weight = 0.0\n",
    "    group_weights = []\n",
    "\n",
    "    for group in groups:\n",
    "        w = sum(class_weight.get(y, 1.0) for y in group)\n",
    "        group_weights.append(w)\n",
    "        total_weight += w\n",
    "\n",
    "    weighted_sum = 0.0\n",
    "    for group, w in zip(groups, group_weights):\n",
    "        if w > 0:\n",
    "            weighted_sum += (w / total_weight) * criterion_function[criterion](group, class_weight)\n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c11676-632d-43f4-a03a-d6aec465c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(X, y, index, value):\n",
    "    \"\"\"\n",
    "    X: matrice delle feature (array NumPy).\n",
    "    y: vettore delle etichette.\n",
    "    index: indice delle feature su cui fare lo split.\n",
    "    value: soglia numerica o categoria.\n",
    "    Restituisce il figlio sinistro e destro in coppia come una lista [X_child, y_child].\n",
    "    \"\"\"\n",
    "    x_index = X[:, index]\n",
    "    # If this feature is numerical.\n",
    "    if x_index.dtype.kind in ['i', 'f']:\n",
    "        mask = x_index >= value\n",
    "    # If this feature is categorical.\n",
    "    else:\n",
    "        mask = x_index == value\n",
    "    # Split into left and right child.\n",
    "    left = [X[~mask, :], y[~mask]]\n",
    "    right = [X[mask, :], y[mask]]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdbdc6b-a665-4be6-8e13-171b34054684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy search function.\n",
    "def get_best_split(X, y, criterion, class_weight):\n",
    "    best_index, best_value, best_score, children = None, None, 1, None\n",
    "    for index in range(len(X[0])):\n",
    "        for value in np.sort(np.unique(X[:, index])):\n",
    "            groups = split_node(X, y, index, value)\n",
    "            impurity = weighted_impurity([groups[0][1], groups[1][1]], criterion, class_weight)\n",
    "            if impurity < best_score:\n",
    "                best_index, best_value, best_score, children = index, value, impurity, groups\n",
    "    return {'index': best_index, 'value': best_value, 'children': children, 'labels': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4c53a9-e72b-4339-8925-78a30d33dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a stopping criterion is met, the process stops at a node, and the major label is assigned to this leaf node.\n",
    "def get_leaf(labels, class_weight):\n",
    "    # Restituisce la classe \"maggioritaria\", pesata; è coerente con weighted_impurity.\n",
    "    counts = np.bincount(labels)\n",
    "    weighted = [\n",
    "        counts[i] * class_weight.get(i, 1.0) for i in range(len(counts))\n",
    "    ]\n",
    "    return np.argmax(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77786267-9a13-45d3-8925-a6f0be68a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function:\n",
    "# 1) it assigns a leaf node if one of two child nodes is empty;\n",
    "# 2) it assigns a leaf node if the current branch depth exceeds the maximum depth allowed;\n",
    "# 3) it assigns a leaf node if the node does not contain sufficient samples required for a further split;\n",
    "# 4) otherwise, it proceeds with a further split with the optimal splitting point.\n",
    "def split(node, max_depth, min_samples_split, depth, criterion, class_weight):\n",
    "    \"\"\"\n",
    "    node: dizionario che rappresenta un nodo dell'albero;\n",
    "    max_depth: profondità massima dell'albero;\n",
    "    min_samples_split: numero minimo di campioni per effettuare un ulteriore split;\n",
    "    depth: profondità attuale del nodo;\n",
    "    criterion: funzione per calcolare la bontà dello split (Gini o entropia).\n",
    "    \"\"\"\n",
    "    left, right = node['children']\n",
    "    del (node['children'])\n",
    "    if left[1].size == 0 and right[1].size == 0:\n",
    "        # Entrambi vuoti --> nodo corrente diventa foglia.\n",
    "        node['leaf'] = get_leaf(node['labels'], class_weight) # labels originali del nodo.\n",
    "        return\n",
    "    elif left[1].size == 0:\n",
    "        node['right'] = get_leaf(right[1], class_weight)\n",
    "        return\n",
    "    elif right[1].size == 0:\n",
    "        node['left'] = get_leaf(left[1], class_weight)\n",
    "        return\n",
    "    # Check if the current depth exceeds the maximal depth.\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = get_leaf(left[1], class_weight), get_leaf(right[1], class_weight)\n",
    "        return\n",
    "    # Check if the left child has enough samples.\n",
    "    if left[1].size <= min_samples_split:\n",
    "        node['left'] = get_leaf(left[1], class_weight)\n",
    "    else:\n",
    "        # It has enough samples, we further split it.\n",
    "        result = get_best_split(left[0], left[1], criterion, class_weight)\n",
    "        result_left, result_right = result['children']\n",
    "\n",
    "        if result_left[1].size == 0:\n",
    "            node['left'] = get_leaf(result_right[1], class_weight)\n",
    "        elif result_right[1].size == 0:\n",
    "            node['left'] = get_leaf(result_left[1], class_weight)\n",
    "        else:\n",
    "            node['left'] = result\n",
    "            split(node['left'], max_depth, min_samples_split, depth+1, criterion, class_weight)\n",
    "    # Check if the right child has enough samples.\n",
    "    if right[1].size <= min_samples_split:\n",
    "        node['right'] = get_leaf(right[1], class_weight)\n",
    "    else:\n",
    "        # It has enough samples, we further split it.\n",
    "        result = get_best_split(right[0], right[1], criterion)\n",
    "        result_left, result_right = result['children']\n",
    "\n",
    "        if result_left[1].size == 0:\n",
    "            node['right'] = get_leaf(result_right[1], class_weight)\n",
    "        elif result_right[1].size == 0:\n",
    "            node['right'] = get_leaf(result_left[1], class_weight)\n",
    "        else:\n",
    "            node['right'] = result\n",
    "            split(node['right'], max_depth, min_samples_split, depth+1, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1f273b-e33f-458d-be53-8c87ed06cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART (classification and regression tree) algorithm entry point.\n",
    "def train_tree(X_train, y_train, max_depth, min_samples_split, criterion, class_weight):\n",
    "    X = np.array(X_train)\n",
    "    y = np.array(y_train)\n",
    "    root = get_best_split(X, y, criterion, class_weight)\n",
    "    split(root, max_depth, min_samples_split, 1, criterion, class_weight)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600a20c9-4ee5-4309-a4c9-4c4788f8f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that displays the tree.\n",
    "CONDITION = {'numerical': {'yes': '>=', 'no': '<'}, 'categorical': {'yes': 'is', 'no': 'is not'}}\n",
    "\n",
    "def visualize_tree(node, depth=0):\n",
    "    if isinstance(node, dict): # Se node è un dizionario, sono in un nodo interno.\n",
    "        if node['value'].dtype.kind in ['i', 'f']:\n",
    "            condition = CONDITION['numerical']\n",
    "        else:\n",
    "            condition = CONDITION['categorical']\n",
    "        print('{}|- X{} {} {}'.format(depth * ' ', node['index'] + 1, condition['no'], node['value']))\n",
    "        if 'left' in node:\n",
    "            visualize_tree(node['left'], depth+1)\n",
    "        print('{}|- X{} {} {}'.format(depth * ' ', node['index'] + 1, condition['yes'], node['value']))\n",
    "        if 'right' in node:\n",
    "            visualize_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print(f\"{depth * ' '}[{node}]\") # Altrimenti sono in una foglia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66a0c94-63c5-447a-8c69-5d792fe1ca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X1 is not fashion\n",
      " |- X2 is not retired\n",
      "  [1]\n",
      " |- X2 is retired\n",
      "  [0]\n",
      "|- X1 is fashion\n",
      " [0]\n"
     ]
    }
   ],
   "source": [
    "# First test with a toy dataset.\n",
    "X_train = [['tech', 'professional'],\n",
    "          ['fashion', 'student'],\n",
    "          ['fashion', 'professional'],\n",
    "          ['sports', 'student'],\n",
    "          ['tech', 'student'],\n",
    "          ['tech', 'retired'],\n",
    "          ['sports', 'professional']]\n",
    "y_train = [1, 0, 0, 0, 1, 0, 1]\n",
    "tree = train_tree(X_train, y_train, 2, 2, 'gini', {0: 1.0, 1: 5.0})\n",
    "visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ac74bf-87a2-4045-9039-8d1782697199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- X2 < 7\n",
      " |- X1 < 7\n",
      "  [1]\n",
      " |- X1 >= 7\n",
      "  [0]\n",
      "|- X2 >= 7\n",
      " [0]\n"
     ]
    }
   ],
   "source": [
    "# Second test with a toy dataset.\n",
    "X_train_n = [[6, 7],\n",
    "            [2, 4],\n",
    "            [7, 2],\n",
    "            [3, 6],\n",
    "            [4, 7],\n",
    "            [5, 2],\n",
    "            [1, 6],\n",
    "            [2, 0],\n",
    "            [6, 3],\n",
    "            [4, 1]]\n",
    "y_train_n = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "tree = train_tree(X_train_n, y_train_n, 2, 2, 'gini', {0: 1.0, 1: 5.0})\n",
    "visualize_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d9e639-acc9-40ec-aca3-fc304ee6045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To validate the correctness of the weighted CART implementation,\n",
    "# the algorithm was tested on small toy datasets.\n",
    "# The resulting trees clearly show that class weights influence both the choice and the order of splits,\n",
    "# prioritizing the separation of the minority class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
